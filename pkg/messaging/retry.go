package messaging

import (
	"context"
	"fmt"
	"log"
	"time"

	pb "marketplace/pkg/proto/events"

	"github.com/segmentio/kafka-go"
	"google.golang.org/protobuf/proto"
	"google.golang.org/protobuf/types/known/timestamppb"
)

// handleFailure, mesaj iÅŸleme sÄ±rasÄ±nda oluÅŸan hatalarÄ± yÃ¶netir.
// Neden DeÄŸiÅŸti? ArtÄ±k reader ve kafkaMsg almÄ±yor; Ã§Ã¼nkÃ¼ mesaj ana akÄ±ÅŸta zaten commit edildi.
// Bu fonksiyon sadece mesajÄ±n tekrar denenip denenmeyeceÄŸine veya DLQ'ya gidip gitmeyeceÄŸine karar verir.
func (kc *KafkaClient) handleFailure(ctx context.Context, message *pb.Message, err error) {
	if err != nil {
		message.LastError = err.Error()
	}

	// Yeniden deneme (Retry) limiti dolmadÄ±ysa tekrar gÃ¶nder
	if kc.shouldRetry(message) {
		message.RetryCount++
		log.Printf("âŸ³ [Failure] Retrying [id=%s, count=%d]", message.Id, message.RetryCount)
		kc.sendToRetry(ctx, message)
	} else {
		// Limit dolduysa mesajÄ± Dead Letter Queue (DLQ) topic'ine at
		log.Printf("âš  [Failure] Max retries reached, sending to DLQ [id=%s]", message.Id)
		kc.sendToDLQ(ctx, message, err)
	}
}

// sendToRetry, mesajÄ± gecikmeli olarak tekrar iÅŸlenmek Ã¼zere Retry Topic'ine gÃ¶nderir.
// Neden? 'Exponential Backoff' algoritmasÄ± kullanarak sistemin (veya veritabanÄ±nÄ±n)
// toparlanmasÄ± iÃ§in zaman tanÄ±r. Ä°lk hata 5sn, ikinci 10sn, Ã¼Ã§Ã¼ncÃ¼ 20sn bekletir.
func (kc *KafkaClient) sendToRetry(ctx context.Context, msg *pb.Message) {
	if kc.retryProducer == nil {
		log.Printf("âœ— [Retry] CRITICAL: Retry producer nil! Sending [id=%s] directly to DLQ", msg.Id)
		kc.sendToDLQ(ctx, msg, fmt.Errorf("retry producer not configured"))
		return
	}

	// Gecikme sÃ¼resini hesapla ve mesajÄ±n Ã¼zerine 'RetryAfter' olarak damgala
	delaySeconds := kc.calculateRetryDelay(int(msg.RetryCount))
	retryTime := time.Now().Add(time.Duration(delaySeconds) * time.Second)
	msg.RetryAfter = timestamppb.New(retryTime)

	messageBytes, _ := proto.Marshal(msg)

	retryCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()

	err := kc.retryProducer.WriteMessages(retryCtx, kafka.Message{
		Key:   []byte(msg.Id),
		Value: messageBytes,
		Headers: []kafka.Header{
			{Key: "RetryCount", Value: []byte(fmt.Sprintf("%d", msg.RetryCount))},
			{Key: "RetryAfter", Value: []byte(retryTime.Format(time.RFC3339))},
		},
	})

	if err != nil {
		log.Printf("âœ— [Retry] Write failed: %v", err)
		// Kafka yazamazsa yine DLQ'ya yedekle
		kc.sendToDLQ(ctx, msg, err)
	} else {
		log.Printf("âŸ³ [Retry] Success: Scheduled for %v (Delay: %ds)",
			retryTime.Format("15:04:05"), delaySeconds)
	}
}

// calculateRetryDelay, 'Exponential Backoff' stratejisi ile bekleme sÃ¼resi Ã¼retir.
// Neden? Hata anÄ±nda servisi mesaj yaÄŸmuruna tutmak yerine (thundering herd),
// aradaki sÃ¼reyi katlayarak aÃ§ar.
func (kc *KafkaClient) calculateRetryDelay(retryCount int) int {
	// FormÃ¼l: 5 * 2^(retryCount-1) -> 5, 10, 20, 40...
	if retryCount <= 1 {
		return 5
	}
	delay := 5 << (retryCount - 1)

	// Maksimum 5 dakika (300sn) sÄ±nÄ±r koyuyoruz
	if delay > 300 {
		return 300
	}
	return delay
}

// shouldRetry, yapÄ±landÄ±rmadaki MaxRetries deÄŸerine gÃ¶re kontrol yapar.
func (kc *KafkaClient) shouldRetry(msg *pb.Message) bool {
	return kc.config.EnableRetry && int(msg.RetryCount) < kc.config.MaxRetries
}

// sendToDLQ, hata alan mesajlarÄ± DLQ topic'ine gÃ¶nderir.
func (kc *KafkaClient) sendToDLQ(ctx context.Context, msg *pb.Message, errReason error) {
	if kc.config.DLQTopic == "" {
		log.Printf("âœ— [DLQ] Not configured for [id=%s]", msg.Id)
		return
	}

	// DLQ iÃ§in geÃ§ici bir writer oluÅŸturuyoruz (Genelde DLQ trafiÄŸi azdÄ±r)
	dlqProducer := &kafka.Writer{
		Addr:         kafka.TCP(kc.config.Brokers...),
		Topic:        kc.config.DLQTopic,
		Balancer:     &kafka.LeastBytes{},
		RequiredAcks: kafka.RequireOne,
	}
	defer dlqProducer.Close()

	messageBytes, _ := proto.Marshal(msg)

	kafkaMsg := kafka.Message{
		Key:   []byte(msg.Id),
		Value: messageBytes,
		Headers: []kafka.Header{
			{Key: "ErrorReason", Value: []byte(errReason.Error())},
			{Key: "OriginalTopic", Value: []byte(kc.config.Topic)},
			{Key: "FailedAt", Value: []byte(time.Now().Format(time.RFC3339))},
		},
	}

	if err := dlqProducer.WriteMessages(ctx, kafkaMsg); err != nil {
		log.Printf("âœ— [DLQ] Send failed: %v", err)
	} else {
		log.Printf("âš  [DLQ] Message moved to DLQ: %s", msg.Id)
	}
}

// ConsumeDLQWithRecovery, DLQ'daki mesajlarÄ± kurtarmaya Ã§alÄ±ÅŸÄ±r.
func (kc *KafkaClient) ConsumeDLQWithRecovery(ctx context.Context, handler MessageHandler) error {
	if kc.config.DLQTopic == "" {
		return fmt.Errorf("DLQ topic not configured")
	}

	reader := kafka.NewReader(kafka.ReaderConfig{
		Brokers:     kc.config.Brokers,
		GroupID:     kc.serviceType.String() + "-dlq-recovery",
		Topic:       kc.config.DLQTopic,
		StartOffset: kafka.FirstOffset, // En baÅŸtan baÅŸla ki hiÃ§bir ÅŸey kaÃ§masÄ±n
	})
	defer reader.Close()

	for {
		m, err := reader.FetchMessage(ctx)
		if err != nil {
			return err
		}

		var message pb.Message
		if err := proto.Unmarshal(m.Value, &message); err != nil {
			reader.CommitMessages(ctx, m)
			continue
		}

		// KRÄ°TÄ°K MESAJ KONTROLÃœ: EÄŸer kritikse hem diske yaz hem kurtar
		if kc.isCriticalMessageType(message.Type) {
			log.Printf("ğŸ†˜ [Recovery] Critical message found: %s", message.Id)
			kc.saveCriticalMessageToStorage(&message)
		}

		// Handler ile tekrar dene
		if err := handler(ctx, &message); err == nil {
			log.Printf("âœ¨ [Recovery] Success for id: %s", message.Id)
			reader.CommitMessages(ctx, m)
		}
	}
}

// handleFailureAfterDelay, gecikmeli (retry) olarak iÅŸlenen bir mesaj tekrar hata aldÄ±ÄŸÄ±nda ne olacaÄŸÄ±nÄ± belirler.
func (kc *KafkaClient) handleFailureAfterDelay(ctx context.Context, message *pb.Message, err error) {
	if err != nil {
		message.LastError = err.Error()
	}

	if kc.shouldRetry(message) {
		message.RetryCount++
		log.Printf("âŸ³ [Retry] Re-scheduling after delayed failure [id=%s, count=%d]", message.Id, message.RetryCount)
		kc.sendToRetry(ctx, message)
	} else {
		log.Printf("âš  [Retry] Max retries reached for delayed message [id=%s]", message.Id)
		kc.sendToDLQ(ctx, message, err)
	}
}
